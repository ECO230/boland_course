{"title":"ECO 230 Section 012","markdown":{"yaml":{"title":"ECO 230 Section 012","author":"Mike Boland, MBA","format":{"revealjs":{"theme":["default","../shared/styles/boland-reveal.scss"],"css":"../shared/styles/accessibility.css","slide-number":true,"hash":true,"controls":true,"transition":"fade","pdf-export":true,"toc":false,"self-contained":false,"center":false,"margin":0}},"execute":{"echo":false}},"headingText":"Can you trust this conclusion?","containsRefs":false,"markdown":"\n\n\n```{r setup, include=FALSE}\n# Global libraries and helpers (loaded once)\nlibrary(readr);  library(dplyr);  library(tidyr);  library(lubridate)\nlibrary(stringr); library(glue);  library(here);   library(scales); library(gt)\nlibrary(eco230r)\n\nset.seed(20260126)\n\n# Reusable GT slide theme\nsource(here(\"shared\",\"scripts\",\"gt_boland.R\"), local = TRUE)\n\n# Small util for truncation used in multiple chunks\n.trunc <- function(x, width) ifelse(is.na(x), x, stringr::str_trunc(x, width = width, side = \"right\", ellipsis = \"â€¦\"))\n```\n\n## Use Instant Booking Wisely\n\n<br> Airbnb Owners should enable **Instant Booking** in Fall â€” it's the unequivocally best season for superior ratings and returns. <br><br>\n\n```{r airbnb}\n# --- Adjust the path to where your file lives ---\ndata_path     <- here(\"shared\", \"data\", \"airbnb_chicago.csv\")\ndata_path_sim <- here(\"week01\",\"data\",\"airbnb_chicago_two_properties_bookings_sim.csv\")\n\n# 1) Load data --------------------------------------------------------------\nabnb     <- read_csv(data_path, show_col_types = FALSE)\nabnb_sim <- read_csv(data_path_sim, show_col_types = FALSE)\n\n# 2) Coerce instant_bookable into logical (t/f/TRUE/FALSE variants) --------\nabnb <- abnb %>% mutate(instant_bookable = tolower(as.character(instant_bookable)) %in% c(\"t\",\"true\"))\n\n# 3) Parse the three date-like columns (WRONG on purpose for teaching) ------\nabnb <- abnb %>%\n  mutate(\n    first_review = suppressWarnings(mdy(first_review)),\n    host_since   = suppressWarnings(mdy(host_since)),\n    last_review  = suppressWarnings(mdy(last_review))\n  )\n\n# 4) Stack the three columns into one fake \"booking date\" ------------------\nlong_wrong <- abnb %>%\n  select(\n    id, listed_price, review_scores_rating, instant_bookable,\n    first_review, host_since, last_review\n  ) %>%\n  pivot_longer(\n    cols = c(first_review, host_since, last_review),\n    names_to   = \"which_date\",\n    values_to  = \"fake_booking_date\"\n  ) %>%\n  filter(!is.na(fake_booking_date))\n\n# 5) Derive a naive season from the calendar month -------------------------\nlong_wrong <- long_wrong %>%\n  mutate(\n    Season = case_when(\n      month(fake_booking_date) %in% c(12, 1, 2) ~ \"Winter\",\n      month(fake_booking_date) %in% c(3, 4, 5)  ~ \"Spring\",\n      month(fake_booking_date) %in% c(6, 7, 8)  ~ \"Summer\",\n      TRUE                                      ~ \"Fall\"\n    )\n  )\n\n# 6) Build the gloriously wrong seasonal summary ---------------------------\nseason_summary <- long_wrong %>%\n  group_by(Season) %>%\n  summarise(\n    bookings      = n(),\n    avg_price     = mean(listed_price, na.rm = TRUE),\n    avg_rating    = mean(review_scores_rating, na.rm = TRUE),\n    instant_share = mean(instant_bookable, na.rm = TRUE)\n  ) %>%\n  ungroup() %>%\n  mutate(\n    rating_dollars = avg_rating * avg_price  # ðŸš© nonsense cross-units\n  ) %>%\n  arrange(desc(rating_dollars))\n\nbest_season <- season_summary %>% slice(1) %>% pull(Season)\n```\n\n```{r ab_flawed}\nseason_summary %>%\n  mutate(\n    `Avg Price (USD)` = dollar(avg_price, accuracy = 0.01),\n    `Avg Rating`      = number(avg_rating, accuracy = 0.01),\n    `Instant-Book %`  = percent(instant_share, accuracy = 0.01),\n    `Rating Ã— Price`  = number(rating_dollars, big.mark = \",\", accuracy = 0.01)\n  ) %>%\n  select(\n    Season,\n    `Bookings` = bookings,\n    `Avg Price (USD)`, `Avg Rating`, `Instant-Book %`, `Rating Ã— Price`\n  ) %>%\n  gt() %>%\n  gt_boland(base_size = 20, tight = FALSE) %>%\n  fmt_number(columns = \"Bookings\", decimals = 0, sep_mark = \",\")\n```\n\n## [Sample Airbnb Data]{.sr-only}\n\n```{r ab_detail}\n# 20 rows that should raise eyebrows: these are properties/listings, not bookings.\nhead_20_flags <- abnb %>%\n  select(\n    # IDs & label-like fields that scream \"listing\"\n    id, name, property_type, room_type, neighbourhood, zipcode,\n    # Capacity-level fields (not per-stay)\n    accommodates, bedrooms, beds,\n    # The three date fields we are misusing as bookings (ðŸš©)\n    host_since, first_review, last_review,\n    # Aggregated stats at the listing level (ðŸš© not a single-stay field)\n    number_of_reviews, review_scores_rating,\n    # Price & toggles\n    listed_price, instant_bookable\n  ) %>%\n  slice_head(n = 20)\n\n# Present & format for slides\nhead_20_print <- head_20_flags %>%\n  mutate(\n    instant_bookable   = ifelse(instant_bookable, \"Yes\", \"No\"),\n    listed_price       = dollar(listed_price, accuracy = 0.01),\n    number_of_reviews  = number(number_of_reviews, big.mark = \",\", accuracy = 1),\n    review_scores_rating = number(review_scores_rating, accuracy = 0.01),\n    host_since   = format(as.Date(host_since),   \"%Y-%m-%d\"),\n    first_review = format(as.Date(first_review), \"%Y-%m-%d\"),\n    last_review  = format(as.Date(last_review),  \"%Y-%m-%d\"),\n    name           = .trunc(name,          38),\n    property_type  = .trunc(property_type, 18),\n    room_type      = .trunc(room_type,     18),\n    neighbourhood  = .trunc(neighbourhood, 18),\n    zipcode        = .trunc(as.character(zipcode), 10)\n  )\n\n# Render with strict widths + tight spacing to fit 20 rows on a slide\nab_listings_tbl <- head_20_print %>%\n  select(\n    id, name, property_type, room_type, neighbourhood, zipcode,\n    accommodates, bedrooms, beds,\n    host_since, first_review, last_review,\n    number_of_reviews, review_scores_rating,\n    listed_price, instant_bookable\n  ) %>%\n  gt() %>%\n  cols_label(\n    id = \"ID\", name = \"Name\", property_type = \"Property\", room_type = \"Room\",\n    neighbourhood = \"Neighborhood\", zipcode = \"ZIP\",\n    accommodates = \"Sleeps\", bedrooms = \"BR\", beds = \"Beds\",\n    host_since = \"Host Since\", first_review = \"First Review\", last_review = \"Last Review\",\n    number_of_reviews = \"# Reviews\", review_scores_rating = \"Rating\",\n    listed_price = \"Price\", instant_bookable = \"IB?\"\n  ) %>%\n  cols_width(\n    id ~ px(68), name ~ px(220), property_type ~ px(120), room_type ~ px(110),\n    neighbourhood ~ px(120), zipcode ~ px(78), accommodates ~ px(70),\n    bedrooms ~ px(60), beds ~ px(60), host_since ~ px(100), first_review ~ px(100),\n    last_review ~ px(100), number_of_reviews ~ px(90), review_scores_rating ~ px(80),\n    listed_price ~ px(90), instant_bookable ~ px(50)\n  ) %>%\n  gt_boland(base_size = 8, tight = TRUE)\n\n\nab_listings_tbl\n```\n\n## Before we run any statisticsâ€¦\n\n<br>\n\n::: {.callout-important title=\"Guiding Question\"}\nWhat can go wrong **before** you ever run a statistical test?\n:::\n\n# What is Statistics?\n\n<br>\n\n::: {.callout-note title=\"What can go wrong...\"}\n**How could a wrong question lead to a wrong conclusion?**\n:::\n\n##  {background-image=\"media/images/w01_s03_image.png\" background-position=\"left center\" background-size=\"auto 150%\" background-repeat=\"no-repeat\" fig-alt=\"Photo of several dogs lying on a blanket; playful opener for the topic.\"}\n\n::::: columns\n::: {.column width=\"50%\"}\n:::\n\n::: {.column width=\"50%\"}\nWhat is **Statistics**?\n\nWhat is **Analytics**?\n:::\n:::::\n\n##  {background-image=\"media/images/w01_s03_image.png\" background-position=\"left center\" background-size=\"auto 150%\" background-repeat=\"no-repeat\" fig-alt=\"Three dogs on a blanket: one black, one brown, one with white markings; objective description.\"}\n\n::::: columns\n::: {.column width=\"50%\"}\n:::\n\n::: {.column width=\"50%\"}\n**Analytics** is the **art** of finding out what is in your data.\n:::\n:::::\n\n##  {background-image=\"media/images/w01_s03_image.png\" background-position=\"left center\" background-size=\"auto 150%\" background-repeat=\"no-repeat\" fig-alt=\"We don't need to see every dog in the world to know that most dogs have fur; analogy for inference.\"}\n\n::::: columns\n::: {.column width=\"50%\"}\n:::\n\n::: {.column width=\"50%\"}\nIf you can (with some effort) find the answer with certainty you are using **Analytics**.\n:::\n:::::\n\n##  {background-image=\"media/images/w01_s03_image.png\" background-position=\"left center\" background-size=\"auto 150%\" background-repeat=\"no-repeat\" fig-alt=\"When we need to get specific we need to go beyond analytics. E.g., how much food does the average dog eat?\"}\n\n::::: columns\n::: {.column width=\"50%\"}\n:::\n\n::: {.column width=\"50%\"}\n**Analytics** deals with what you know.\n\n**Statistics** deals with what you do not know.\n:::\n:::::\n\n##  {background-image=\"media/images/w01_s03_image.png\" background-position=\"left center\" background-size=\"auto 150%\" background-repeat=\"no-repeat\" fig-alt=\"Analytics frames the questions; statistics turns data into answers.\"}\n\n::::: columns\n::: {.column width=\"50%\"}\n:::\n\n::: {.column width=\"50%\"}\n**Analytics** turns curiosity into questions.\n\n**Statistics** turns data into answers.\n:::\n:::::\n\n##  {background-image=\"media/images/w01_s03_image.png\" background-position=\"left center\" background-size=\"auto 150%\" background-repeat=\"no-repeat\" fig-alt=\"A picture, a spreadsheet, or a database â€” all are data sources for analytics and statistics.\"}\n\n::::: columns\n::: {.column width=\"50%\"}\n:::\n\n::: {.column width=\"50%\"}\n**Analytics** is the **art** of finding out what is in your data.\n\n**Statistics** is the **science** of making decisions under uncertainty.\n:::\n:::::\n\n##  {background-image=\"media/images/w01_s03_image.png\" background-position=\"left center\" background-size=\"auto 150%\" background-repeat=\"no-repeat\" fig-alt=\"A picture, a spreadsheet, or a database â€” all are data sources for analytics and statistics.\"}\n\n::::: columns\n::: {.column width=\"50%\"}\n:::\n\n::: {.column width=\"50%\"}\n**Analytics** or **Statistics**\n\n-   Count the number of airbnb properties within 1 mile of Wrigley Field\n-   Predict how many bookings an airbnb property will have next year\n-   Testing whether changing cancellation policy *caused* higher satisfaction\n:::\n:::::\n\n::: notes\n-   Open with intuition: students already *do* analytics informally.\n-   Emphasize uncertainty as the key dividing line.\n-   Pause after the third fragment and ask for examples.\n:::\n\n# What does one row represent?\n\n<br>\n\n::: {.callout-note title=\"What can go wrong...\"}\n**Could the Airbnb mistake come from using the wrong unit of analysis?**\n:::\n\n## [Data at different grain levels]{.sr-only}\n\n### Calculate the Total Yearly Revenue for Each Property\n\n:::: fragment\n::: {.callout-important title=\"Gotcha! - Wrong Unit of Analysis\"}\n:::\n::::\n\n```{r ab_grain}\n# Helper (for truncation) already defined in setup chunk\n\n# 1) Identify properties to show -------------------------------------------------\nsim_ids <- abnb_sim %>% distinct(property_id) %>% pull(property_id) %>% sort()\nshow_ids <- head(sim_ids, 2)   # pick two properties for display\n\n# 2) LISTING-LEVEL TABLE (abnb): 10 total properties including the two ----------\ndesired_total <- 10\nnum_needed    <- max(0, desired_total - length(show_ids))\nextra_ids <- abnb %>%\n  filter(!id %in% show_ids) %>%\n  distinct(id) %>%\n  slice_sample(n = num_needed) %>%\n  pull(id)\n\nids_for_abnb_table <- c(show_ids, extra_ids)\n\nabnb_tbl_data <- abnb %>%\n  filter(id %in% ids_for_abnb_table) %>%\n  select(\n    id, name, room_type, listed_price, accommodates, neighbourhood,\n    bedrooms, bathrooms, beds, cancellation_policy,host_since\n  ) %>%\n  arrange(name)\n\ntbl_abnb_vt <- abnb_tbl_data %>%\n  gt() %>%\n  cols_label(\n    id = \"ID\", name = \"Name\", room_type = \"Room\", listed_price = \"List\",\n    accommodates = \"Sleeps\", neighbourhood = \"Nâ€™hood\", bedrooms = \"BR\",\n    bathrooms = \"BA\", beds = \"Beds\", cancellation_policy = \"Cancel\",host_since = \"Host Since\"\n  ) %>%\n  text_transform(\n    locations = cells_body(columns = c(name, neighbourhood, room_type, cancellation_policy)),\n    fn = function(x) .trunc(x, width = 28)\n  ) %>%\n  fmt_currency(columns = listed_price, currency = \"USD\", decimals = 0) %>%\n  cols_width(\n    id ~ px(70), name ~ px(230), room_type ~ px(110), listed_price ~ px(80),\n    accommodates ~ px(75), neighbourhood ~ px(130), bedrooms ~ px(55),\n    bathrooms ~ px(55), beds ~ px(55), cancellation_policy ~ px(110), host_since ~ px(80)\n  ) %>%\n  gt_boland(base_size = 6, tight = TRUE) %>%\n  tab_caption(md(\"**Dataset A** â€” Airbnb Rental Data\"))\n\n# 3) BOOKING-LEVEL TABLE (abnb_sim): sample 5 per property ---------------------\nabnb_sim_tbl_data <- abnb_sim %>%\n  filter(property_id %in% show_ids) %>%\n  transmute(\n    id = property_id, name, room_type, accommodates, neighbourhood,\n    checkin_date = as_date(checkin_date), nights, guest_count, status,\n    price_per_night, total_price = tidyr::replace_na(total_price, 0)\n  ) %>%\n  arrange(name, checkin_date) %>%\n  group_by(id) %>%\n  filter(row_number() %in% sample.int(n(), size = min(5, n()), replace = FALSE)) %>%\n  ungroup() %>%\n  arrange(name, checkin_date)\n\ntbl_abnb_sim_vt <- abnb_sim_tbl_data %>%\n  gt() %>%\n  cols_label(\n    id = \"ID\", name = \"Name\", room_type = \"Room\", accommodates = \"Sleeps\",\n    neighbourhood = \"Nâ€™hood\", checkin_date = \"Checkâ€‘in\", nights = \"Nts\",\n    guest_count = \"Guests\", status = \"Status\", price_per_night = \"Price/Nt\",\n    total_price = \"Total\"\n  ) %>%\n  text_transform(\n    locations = cells_body(columns = c(name, neighbourhood, room_type, status)),\n    fn = function(x) .trunc(x, width = 24)\n  ) %>%\n  fmt_currency(columns = c(price_per_night, total_price), currency = \"USD\", decimals = 0) %>%\n  cols_width(\n    id ~ px(70), name ~ px(220), room_type ~ px(100), accommodates ~ px(75),\n    neighbourhood ~ px(120), checkin_date ~ px(90), nights ~ px(45),\n    guest_count ~ px(60), status ~ px(90), price_per_night ~ px(90),\n    total_price ~ px(100)\n  ) %>%\n  gt_boland(base_size = 6.25, tight = TRUE) %>%\n  tab_caption(md(\"**Dataset B** â€” Airbnb Rental Data\"))\n```\n\n```{r ab_property}\n# Listing-level snapshot (fragment 1)\ntbl_abnb_vt\ntbl_abnb_sim_vt\n```\n\n```{r ab_bookings}\n# Booking-level snapshot (fragment 2)\n\n```\n\n## [Rows vs Columns]{.sr-only}\n\n::::: columns\n::: {.column width=\"50%\"}\n### Columns\n\n![](media/images/w01_s19_image.png){fig-alt=\"Icon emphasizing the concept of columnsâ€”variablesâ€”in a dataset.\" width=\"100%\"}\n:::\n\n::: {.column width=\"50%\"}\n<br><br><br><br><br>\n\n### Rows\n\n![](media/images/w01_s19_image.jpg){fig-alt=\"Icon emphasizing the concept of rowsâ€”observationsâ€”in a dataset.\" width=\"100%\"}\n:::\n:::::\n\n## Unit of Analysis\n\n::::::: columns\n::: column-page\n**What does each *thingie* (row, observation, grain) of this data represent?**\n:::\n\n:::: {.column width=\"58%\"}\n::: tight-list\n-   Everyone in a *zipcode*\n-   Individual consumers\n-   Individual purchases\n-   GDP of an economy\n-   Population of a planet\n:::\n::::\n\n::: {.column width=\"42%\"}\n![](media/images/w01_s14_image.png){fig-alt=\"Photo of several dogs lying on a blanket; playful opener for the topic.\" height=\"65%\"}\n:::\n:::::::\n\n## Unit of Analysis\n\n<br><br>\n\n### Rows are never 'just rows'\n\n<br><br>\n\n::: {.callout-important title=\"Critical Insight\"}\nIf you misunderstand the unit of analysis, **every result is wrong**, even with perfect code.\n:::\n\n## Data Grouping: Cross-Sectional {background-image=\"media/images/w01_s15_image.jpeg\" background-size=\"cover\" background-opacity=\"0.95\" fig-alt=\"Freezeâ€‘frame droplet illustrating a crossâ€‘sectional snapshot at a single point in time.\"}\n\n## Data Grouping: Time-Series\n\n![](media/images/w01_s16_image.jpeg){fig-alt=\"Growth sequence image suggesting change over time in a timeâ€‘series.\" height=\"85%\"}\n\n## Data Grouping: Panel\n\n![](media/images/w01_s17_image.jpeg){.r-stretch fig-alt=\"Gridâ€‘style visual suggesting repeated measures on multiple units across time (panel data).\" fig-align=\"right\" height=\"100%\"}\n\n# Data Structure\n\n<br>\n\n::: {.callout-note title=\"What can go wrong...\"}\n**Could shape of my data change what answers are even possible?**\n:::\n\n## [Tall vs Wide Data]{.sr-only}\n\n### Summarize total minutes of sleep by month and location\n\n:::: fragment\n::: {.callout-important title=\"Gotcha! - Wrong Data Structure\"}\n:::\n::::\n\n```{r sleep_data}\nlibrary(here)\n\n# ---- 1) Load with explicit column types ----\ncsv_path      <- here(\"week01\", \"data\", \"sleep_tracking_Jan-Jun_2025_with_zip.csv\")\ncsv_path_zips <- here(\"week01\", \"data\", \"simulated_zip_profiles.csv\")\n\n# 1) Load data --------------------------------------------------------------\nsleep_zips <- read_csv(csv_path_zips)\n\nsleep <- read_csv(\n  file = csv_path,\n  col_types = cols(\n    Date          = col_character(),\n    DayOfWeek     = col_character(),\n    Month         = col_character(),\n    PersonName    = col_character(),\n    Gender        = col_character(),\n    Location      = col_character(),\n    SleepEventType= col_character(),\n    StartTime     = col_character(),\n    EndTime       = col_character(),\n    TotalMinutes  = col_integer(),\n    REMMinutes    = col_integer(),\n    DeepMinutes   = col_integer(),\n    LightMinutes  = col_integer(),\n    SleepQuality  = col_double(),\n    ZipCode       = col_character()\n  ),\n  show_col_types = FALSE\n)\n\n# ---- 2) Fix Date if it came in as an Excel serial ----\nis_excel_serial <- function(x_chr) {\n  all(str_detect(x_chr, \"^\\\\d{4,5}$\"), na.rm = TRUE)\n}\n\nif (is_excel_serial(sleep$Date)) {\n  sleep$Date <- as.Date(as.numeric(sleep$Date), origin = \"1899-12-30\")\n} else {\n  parsed1 <- suppressWarnings(ymd(sleep$Date, quiet = TRUE))\n  parsed2 <- ifelse(is.na(parsed1), suppressWarnings(mdy(sleep$Date, quiet = TRUE)), parsed1)\n  sleep$Date <- as.Date(parsed2)\n}\n\n# ---- 3) Robust parsers for StartTime/EndTime ----\nparse_start_end <- function(x_chr) {\n  x_chr <- str_trim(x_chr)\n  parse_date_time(\n    x_chr,\n    orders = c(\n      \"Y-m-d H:M\", \"Y-m-d H:M:S\",\n      \"m/d/Y I:M p\", \"m/d/Y I:M:S p\",\n      \"m/d/y I:M p\", \"m/d/y I:M:S p\"\n    ),\n    tz = \"UTC\"\n  )\n}\n\nsleep$StartTime_dt <- parse_start_end(sleep$StartTime)\nsleep$EndTime_dt   <- parse_start_end(sleep$EndTime)\n\nfmt_time_12h <- function(dt) {\n  ifelse(\n    is.na(dt), NA_character_,\n    str_to_upper(format(dt, \"%I:%M %p\")) |>\n      str_replace(\"^0\", \"\") |>\n      str_replace_all(\"AM\", \"A.M.\") |>\n      str_replace_all(\"PM\", \"P.M.\")\n  )\n}\n\nfmt_pct <- function(x) paste0(round(100 * x), \"%\")\n```\n\n```{r sleep_filter}\nweek_data <- sleep %>%\n  filter(\n    Date >= \"2025-01-05\",\n    Date <= \"2025-01-11\",\n    PersonName %in% c(\"Mike\", \"Cam\"),\n    SleepEventType == \"Main\"\n  ) %>%\n  select(\n    Name = PersonName, Gender, Location, Date, DayOfWeek, TotalMinutes\n  ) %>%\n  group_by(Name, Gender, Location, Date, DayOfWeek) %>%\n  summarise(TotalMinutes = sum(TotalMinutes), .groups = \"drop\")\n```\n\n::::: columns\n::: {.column width=\"30%\"}\n```{r sleep_tall}\n\n\n\ntall_week <- sleep %>%\n  filter(\n    Date >= \"2025-01-05\",\n    Date <= \"2025-01-11\",\n    PersonName %in% c(\"Mike\", \"Cam\"),\n    SleepEventType == \"Main\"\n  ) %>%\n  select(\n    Name = PersonName, Gender, Location, Date, DayOfWeek, TotalMinutes\n  ) %>%\n  group_by(Name, Gender, Location, Date, DayOfWeek) %>%\n  summarise(TotalMinutes = sum(TotalMinutes), .groups = \"drop\") %>%\n  mutate(across(-Name, as.character)) %>%\n  pivot_longer(cols = -Name, names_to = \"Variable\", values_to = \"Value\") %>%\n  arrange(Name, Variable)\n\n\ntall_week %>%\n  gt(rowname_col = \"Name\") %>%\n  tab_header(title = md(\"**Tall â€” More rows, fewer columns**\")) %>%\n  cols_label(Variable = \"Variable\", Value = \"Value\") %>%\n  fmt_missing(everything(), missing_text = \"\") %>%\n  gt_boland(base_size = 12, tight = FALSE) %>%\n  tab_options(\n    container.height = px(420),\n    container.overflow.y = TRUE\n  )\n```\n:::\n\n::: {.column width=\"70%\"}\n```{r sleep_wide}\nwide_week <- week_data %>%\n  select(Name, Gender, Location, Date, TotalMinutes) %>%\n  pivot_wider(names_from = Date, values_from = TotalMinutes) %>%\n  arrange(Name)\n\nwide_week %>%\n  gt() %>%\n  tab_header(title = md(\"**Wide â€” More columns, fewer rows**\")) %>%\n  fmt_missing(everything(), missing_text = \"\") %>%\n  gt_boland(base_size = 12, tight = FALSE) %>%\n  tab_options(container.overflow.x = TRUE, table.width = pct(120))\n```\n:::\n:::::\n\n## Data Types\n\n<br>\n\n### Categories\n\nTrue/False â†’ `logical`\\\nCategorical â†’ `factor`\\\nOrdinal â†’ `factor`\n\n<br>\n\n### Numbers\n\nDiscrete â†’ `integer`\\\nContinuous â†’ `double`\n\n------------------------------------------------------------------------\n\n## Measurement Scales\n\n![](../shared/images/NOIR.svg){width=\"100%\" height=\"700px\" fig-alt=\"Visual representing measurement scales Nominal, Ordinal, Interval, Ratio and their common uses.\"}\n\n## Observations - Atomic Data\n\n```{r name:sleep_desc}\n# ---- 5) Function to build the two tables for a chosen person & date ----\nmake_sleep_tables <- function(data, person = \"Mike\", date_input = \"2025-01-03\") {\n  date_val <- if (inherits(date_input, \"Date\")) date_input else as.Date(date_input)\n  row <- data %>%\n    filter(PersonName == person, Date == date_val, SleepEventType == \"Main\") %>%\n    arrange(StartTime_dt) %>% slice(1)\n  if (nrow(row) == 0) stop(\"No 'Main' sleep row found for that person/date.\")\n\n  categories_df <- tibble::tibble(\n    Label = c(\"Name\", \"Date\", \"Gender\", \"Location\", \"ZipCode\"),\n    Value = c(row$PersonName, format(row$Date, \"%m/%d/%Y\"), row$Gender, row$Location, row$ZipCode)\n  )\n  numbers_df <- tibble::tibble(\n    Label = c(\"Start Time\", \"End Time\", \"R.E.M.\", \"Deep Sleep\", \"Light Sleep\", \"Total Sleep\", \"Quality\"),\n    Value = c(\n      fmt_time_12h(row$StartTime_dt), fmt_time_12h(row$EndTime_dt),\n      paste0(row$REMMinutes, \" Minutes\"), paste0(row$DeepMinutes, \" Minutes\"),\n      paste0(row$LightMinutes, \" Minutes\"), as.character(row$TotalMinutes), fmt_pct(row$SleepQuality)\n    )\n  )\n  list(categories = categories_df, numbers = numbers_df)\n}\n\ntables <- make_sleep_tables(sleep, person = \"Mike\", date_input = \"2025-01-03\")\ncategories_df <- tables$categories\nnumbers_df    <- tables$numbers\n```\n\n:::::: columns\n::: {.column width=\"30%\"}\n```{r sleep_categories}\n\ncategories_df |>\n  gt() |>\n  tab_header(title = md(\"**Categories**\")) |>\n  cols_label(Label = \"\", Value = \"\") |>\n  gt_boland(base_size = 12, tight = FALSE)\n```\n:::\n\n::: {.column width=\"40%\"}\n![](media/images/w01_s21_image.jpeg){fig-alt=\"Single cube emphasizing an atomic unit of observation in the data.\" width=\"100%\"}\n:::\n\n::: {.column width=\"30%\"}\n```{r sleep_numbers}\n\nnumbers_df |>\n  gt() |>\n  tab_header(title = md(\"**Numbers**\")) |>\n  cols_label(Label = \"\", Value = \"\") |>\n  gt_boland(base_size = 12, tight = FALSE)\n```\n:::\n::::::\n\n## [Summarized Data]{.sr-only}\n\n:::::::::: columns\n:::: {.column width=\"30%\"}\n### Dimensions\n\n::: tight-list\n-   Categories\n-   Filters\n-   Axis Labels\n:::\n::::\n\n::: {.column width=\"40%\"}\n<br> <br> <br> <br> ![](media/images/w01_s22_stack.png){fig-alt=\"An ordered stack of multiple atomic units making it possible to summarize the data with measures and summary statistics.\" width=\"100%\"}\n:::\n\n:::::: {.column width=\"30%\"}\n### Measures\n\n::: tight-list\n-   Averages\n-   Standard Deviation\n-   Counts\n-   Sums\n:::\n\n::: fragment\n```{r sleep_summary}\njune_glamping <- sleep %>% filter(Month == \"June\", Location == \"Camping\")\n# june_glamping <- june_glamping %>% filter(SleepEventType == \"Main\")\n\nmean_minutes   <- mean(june_glamping$TotalMinutes, na.rm = TRUE)\nmedian_minutes <- median(june_glamping$TotalMinutes, na.rm = TRUE)\navg_quality    <- mean(june_glamping$SleepQuality, na.rm = TRUE)\nn_records      <- nrow(june_glamping)\n\nsummary_vertical <- tibble::tibble(\n  Summary = c(\n    glue(\"Mean = {sprintf('%.2f', mean_minutes)} Minutes\"),\n    glue(\"Median = {round(median_minutes)} Minutes\"),\n    glue(\"Quality = {percent(avg_quality, accuracy = 0.01)}\"),\n    glue(\"N Records = {comma(n_records)}\")\n  )\n)\n\nsummary_vertical |>\n  gt() |>\n  tab_header(title = md(\"**June Camping**\")) |>\n  cols_label(Summary = \"\") |>\n  gt_boland(base_size = 16, tight = FALSE)\n```\n:::\n\n::: fragment\n```{r sleep_summary_jan}\njan_home <- sleep %>% filter(Month == \"January\", Location == \"Home\")\n# june_glamping <- june_glamping %>% filter(SleepEventType == \"Main\")\n\nmean_minutes_JH   <- mean(jan_home$TotalMinutes, na.rm = TRUE)\nmedian_minutes_JH <- median(jan_home$TotalMinutes, na.rm = TRUE)\navg_quality_JH    <- mean(jan_home$SleepQuality, na.rm = TRUE)\nn_records_JH     <- nrow(jan_home)\n\nsummary_vertical <- tibble::tibble(\n  Summary = c(\n    glue(\"Mean = {sprintf('%.2f', mean_minutes_JH)} Minutes\"),\n    glue(\"Median = {round(median_minutes_JH)} Minutes\"),\n    glue(\"Quality = {percent(avg_quality_JH, accuracy = 0.01)}\"),\n    glue(\"N Records = {comma(n_records_JH)}\")\n  )\n)\n\nsummary_vertical |>\n  gt() |>\n  tab_header(title = md(\"**January Home**\")) |>\n  cols_label(Summary = \"\") |>\n  gt_boland(base_size = 16, tight = FALSE)\n```\n:::\n::::::\n::::::::::\n\n## Tall vs Wide\n\n```{r sleep_dims_cats}\n# --- Define columns ---\ndims <- c(\"Date\",\"DayOfWeek\",\"Month\",\"PersonName\",\"Gender\",\"Location\",\"SleepEventType\")\nmeas <- c(\"StartTime\",\"EndTime\",\"TotalMinutes\",\"REMMinutes\",\"DeepMinutes\",\"LightMinutes\",\"SleepQuality\")\n\ntbl20 <- sleep %>% select(all_of(dims), all_of(meas)) %>% slice_head(n = 15)\n\n# Tableau-like colors (approx)\ntableau_blue  <- \"#4E79A7\"\ntableau_green <- \"#59A14F\"\nblue_fill     <- \"#EAF2FB\"\ngreen_fill    <- \"#EAF6EA\"\nheader_text   <- \"white\"\n\n\ntbl20 |>\n  gt() |>\n  tab_spanner(label = \"Dimensions\", columns = all_of(dims)) |>\n  tab_spanner(label = \"Measures\",   columns = all_of(meas)) |>\n  fmt_percent(columns = \"SleepQuality\", decimals = 2) |>\n  tab_style(style = cell_fill(color = blue_fill),  locations = cells_body(columns = all_of(dims))) |>\n  tab_style(style = cell_fill(color = green_fill), locations = cells_body(columns = all_of(meas))) |>\n  tab_style(style = list(cell_fill(color = tableau_blue),  cell_text(color = header_text)), locations = cells_column_spanners(spanners = \"Dimensions\")) |>\n  tab_style(style = list(cell_fill(color = tableau_green), cell_text(color = header_text)), locations = cells_column_spanners(spanners = \"Measures\")) |>\n  gt_boland(base_size = 12, tight = FALSE) |>\n  cols_label(\n    SleepEventType = \"EventType\",\n    REMMinutes = \"REMMinutes\", DeepMinutes = \"DeepMinutes\",\n    LightMinutes = \"LightMinutes\", TotalMinutes = \"TotalMinutes\",\n    SleepQuality = \"SleepQuality\"\n  )\n```\n\n## Principles of Tidy Data\n\n<br>\n\n-   *Each variable you measure should be in one column*\n-   *Each observation of that variable should be in a different row*\n-   *There should be one table for each type of observational unit*\n-   *If you have multiple tables you need a key to link them*\n\n<br><br><br>\n\n:::: fragment\n::: {.callout-important title=\"Nerd Alert.\"}\nTidy Data principles are a **solution to a problem**, not rules that **must** be followed.\n:::\n::::\n\n```{r tidy_tables}\n# ---------- TABLE A: sleep (first 10 rows with selected columns) ----------\nsleep_tbl_data <- sleep %>% select(PersonName, Gender, Location, ZipCode, TotalMinutes, SleepQuality) %>% head(10)\n\n\t\t# Render A\nsleep_tbl <- sleep_tbl_data %>%\n  gt() %>%\n  cols_label(\n    PersonName = \"Name\", Gender = \"Gender\", Location = \"Location\",\n    ZipCode = \"ZIP\", TotalMinutes = \"Minutes\", SleepQuality = \"Quality\"\n  ) %>%\n  cols_width(\n    PersonName ~ px(180), Gender ~ px(90), Location ~ px(130), ZipCode ~ px(90),\n    TotalMinutes ~ px(90), SleepQuality ~ px(90)\n  ) %>%\n  gt_boland(base_size = 16, tight = TRUE) %>%\n  tab_caption(md(\"**Sleep (first 10):** `PersonName, Gender, Location, ZipCode, TotalMinutes, SleepQuality`\"))\n\n# ---------- TABLE B: sleep_zips (first 10 rows) ----------\nsleep_zips_tbl_data <- sleep_zips %>% head(10)\n\nsleep_zips_tbl <- sleep_zips_tbl_data %>%\n  gt() %>%\n  cols_label(\n    zip = \"ZIP\", city = \"City\", state = \"State\", population = \"Population\",\n    crime_rate_per_100k = \"Crime per 100k\", avg_sunny_days_per_year = \"Sunny Days\"\n  ) %>%\n  fmt_number(columns = population,              decimals = 0, sep_mark = \",\") %>%\n  fmt_number(columns = crime_rate_per_100k,     decimals = 0, sep_mark = \",\") %>%\n  fmt_number(columns = avg_sunny_days_per_year, decimals = 0) %>%\n  cols_width(\n    zip ~ px(90), city ~ px(150), state ~ px(70), population ~ px(110),\n    crime_rate_per_100k ~ px(120), avg_sunny_days_per_year ~ px(100)\n  ) %>%\n  gt_boland(base_size = 16, tight = TRUE) %>%\n  tab_caption(md(\"**Sleep ZIP Profiles (first 10):** `zip, city, state, population, crime_rate_per_100k, avg_sunny_days_per_year`\"))\n```\n\n## Tidy Data - Principles 1-3\n\n```{r tidy_base}\n# ---- Display both tables on the slide ----\nsleep_tbl\n```\n\n## Tidy Data - Principle 4\n\n```{r tidy_join}\nsleep_zips_tbl\n```\n\n# Acronyms to the Rescue (ATTR)\n\n<br>\n\n::: {.callout-note title=\"What can go wrong...\"}\n**Could messy or inconsistent data break every conclusion downstream?**\n:::\n\n## [ETL Process - Extract]{.sr-only}\n\n::: text-center\n**Extract** \\| Transform \\| Load\n:::\n\n:::::: columns\n::: {.column width=\"33%\"}\nStructured Data\n\n![](media/images/w01_s11_database.png){fig-alt=\"Icon illustrating extracting from an ordered database in the ETL workflow.\" width=\"80%\"}\n:::\n\n::: {.column width=\"34%\"}\nThird Party\n\n![](media/images/w01_s11_census.png){fig-alt=\"Icon illustrating extracting from a third party source of structured data in the ETL workflow.\" width=\"80%\"}\n:::\n\n::: {.column width=\"33%\"}\nUnstructured Data\n\n![](media/images/w01_s11_image.png){fig-alt=\"Terminal/connector graphic showing extracted data may be unstructured or streaming ETL operations.\" width=\"80%\"}\n:::\n::::::\n\n## [ETL Process - Transform]{.sr-only}\n\n::::::: text-center\nExtract \\| **Transform** \\| Load\n\n:::::: columns\n::: {.column width=\"25%\"}\n![](../shared/images/logo_Excel.png){width=\"100px\" fig-alt=\"Microsoft Excel Logo\"}\n\n![](media/images/w01_s11_census.png){width=\"100px\" fig-alt=\"Icon illustrating extracting from a third party source of structured data in the ETL workflow.\"}\n\n![](../shared/images/logo_R.png){width=\"100px\" fig-alt=\"R Language Logo\"}\n\n![](../shared/images/logo_Database.png){width=\"100px\" fig-alt=\"Generic Database Logo\"}\n\n![](media/images/w01_s11_image.png){width=\"100px\" fig-alt=\"Terminal/connector graphic showing extracted data may be unstructured or streaming ETL operations.\"}\n:::\n\n::: {.column width=\"50%\"}\n![](media/images/w01_s20_grinder.png){width=\"100%\" fig-alt=\"Transformation metaphor: grinder processing data.\"}\n:::\n\n::: {.column width=\"25%\"}\n:::\n::::::\n:::::::\n\n## [ETL Process - Transform Example]{.sr-only}\n\n::: text-center\nExtract \\| **Transform** \\| Load\n:::\n\n```{r}\n# ---- 0) Where the file lives ----\npath <- here(\"week01\", \"data\", \"messy_zip_54601.csv\")\n\n# ---- 1) Load the messy data (20 rows) ----\nmessy_zip <- read_csv(path, show_col_types = FALSE)\n\n# ---- 2) Truncate the very long column so the table fits on a slide ----\nTRUNC_WIDTH <- 60\nmessy_zip_trunc <- messy_zip %>%\n  mutate(\n    everything_raw = ifelse(\n      is.na(everything_raw),\n      everything_raw,\n      str_trunc(everything_raw, width = TRUNC_WIDTH, side = \"right\", ellipsis = \"â€¦\")\n    )\n  )\n\n# ---- 3) Render ALL 20 rows with slide theme ----\nmessy_zip_trunc %>%\n  select(zip_value,state_value,county_value,population_value,fips_county,everything_raw) %>%\n  gt() %>%\n  cols_width(\n    zip_value ~ px(110), state_value ~ px(110), county_value ~ px(140),\n    population_value ~ px(130), fips_county ~ px(95), everything_raw ~ px(380)\n  ) %>%\n  gt_boland(base_size = 10, tight = TRUE) %>%\n  tab_caption(md(\"**Messy ZIP 54601**\"))\n```\n\n## [ETL Process - Load]{.sr-only}\n\n::::::: text-center\nExtract \\| Transform \\| **Load**\n\n:::::: columns\n::: {.column width=\"25%\"}\n![](../shared/images/logo_Excel.png){width=\"100px\" fig-alt=\"Microsoft Excel Logo\"}\n\n![](media/images/w01_s11_census.png){width=\"100px\" fig-alt=\"Icon illustrating extracting from a third party source of structured data in the ETL workflow.\"}\n\n![](../shared/images/logo_R.png){width=\"100px\" fig-alt=\"R Language Logo\"}\n\n![](../shared/images/logo_Database.png){width=\"100px\" fig-alt=\"Generic Database Logo\"}\n\n![](media/images/w01_s11_image.png){width=\"100px\" fig-alt=\"Terminal/connector graphic showing extracted data may be unstructured or streaming ETL operations.\"}\n:::\n\n::: {.column width=\"50%\"}\n![](media/images/w01_s20_grinder.png){width=\"100%\" fig-alt=\"Transformation metaphor: grinder processing data.\"}\n:::\n\n::: {.column width=\"25%\"}\n![](../shared/images/logo_Tableau.jpeg){width=\"100px\" fig-alt=\"Tableau Logo\"}\n\n![](../shared/images/logo_Database.png){width=\"100px\" fig-alt=\"Generic Database Logo\"}\n\n![](../shared/images/logo_Excel.png){width=\"100px\" fig-alt=\"Microsoft Excel Logo\"}\n\n![](../shared/images/logo_R.png){width=\"100px\" fig-alt=\"R Language Logo\"}\n\n![](../shared/images/logo_SPSS.png){width=\"100px\" fig-alt=\"SPSS Logo\"}\n:::\n::::::\n:::::::\n\n## Tableau\n\n![](media/images/w01_s26_image.png){fig-alt=\"Tableau branding indicating the visualization tool introduced in this course.\" width=\"100%\"}\n\n## Posit.cloud\n\n![](media/images/w01_s27_image.png){fig-alt=\"Posit Cloud branding indicating a browserâ€‘based RStudio environment for analysis.\" width=\"100%\"}\n\n## [Coding in R]{.sr-only}\n\n```{r setup_eco}\nlibrary(eco230r)\nlibrary(dplyr)\n```\n\n::::::::: columns\n::: {.column width=\"10%\"}\n![](../shared/images/logo_R.png){width=\"100%\" fig-alt=\"R Language Logo\"}\n:::\n\n::::::: {.column width=\"90%\"}\n::: fragment\n```{r idt_code, echo=TRUE, results=\"hide\"}\nabnb %>% idt(listed_price~instant_bookable)\n```\n:::\n\n::: fragment\n```{r idt_results, echo=FALSE, results=\"show\"}\nabnb %>% idt(listed_price~instant_bookable)\n```\n:::\n\n::: fragment\n```{r ano_code, echo=TRUE, results=\"hide\" }\nabnb %>% ano(listed_price~room_type)\n```\n:::\n\n::: fragment\n```{r ano_results, echo=FALSE, results=\"show\" }\nabnb %>% ano(listed_price~room_type)\n```\n:::\n:::::::\n:::::::::\n\n## Soâ€¦ what actually went wrong with the Airbnb analysis?\n\n<br>\n\n::: tight-list\n-   Wrong unit of analysis\\\n-   Wrong time fields\\\n-   Wrong data structure\\\n-   Wrong aggregation\\\n-   Wrong assumptions about what the data measures\\\n:::\n\n<br>\n\n::: {.callout-tip title=\"What is your data?\"}\nEverything broke *before* statistics.\n:::\n\n## [Summary and Prime Directive]{.sr-only}\n\n<br><br><br>\n\n### Before running any statistics, what are the three questions you must answer about a dataset?\n\n<br> 1. What does one row represent? <br> 2. What kind of variables do I have? <br> 3. What question can this data answer?","srcMarkdownNoYaml":"\n\n# Can you trust this conclusion?\n\n```{r setup, include=FALSE}\n# Global libraries and helpers (loaded once)\nlibrary(readr);  library(dplyr);  library(tidyr);  library(lubridate)\nlibrary(stringr); library(glue);  library(here);   library(scales); library(gt)\nlibrary(eco230r)\n\nset.seed(20260126)\n\n# Reusable GT slide theme\nsource(here(\"shared\",\"scripts\",\"gt_boland.R\"), local = TRUE)\n\n# Small util for truncation used in multiple chunks\n.trunc <- function(x, width) ifelse(is.na(x), x, stringr::str_trunc(x, width = width, side = \"right\", ellipsis = \"â€¦\"))\n```\n\n## Use Instant Booking Wisely\n\n<br> Airbnb Owners should enable **Instant Booking** in Fall â€” it's the unequivocally best season for superior ratings and returns. <br><br>\n\n```{r airbnb}\n# --- Adjust the path to where your file lives ---\ndata_path     <- here(\"shared\", \"data\", \"airbnb_chicago.csv\")\ndata_path_sim <- here(\"week01\",\"data\",\"airbnb_chicago_two_properties_bookings_sim.csv\")\n\n# 1) Load data --------------------------------------------------------------\nabnb     <- read_csv(data_path, show_col_types = FALSE)\nabnb_sim <- read_csv(data_path_sim, show_col_types = FALSE)\n\n# 2) Coerce instant_bookable into logical (t/f/TRUE/FALSE variants) --------\nabnb <- abnb %>% mutate(instant_bookable = tolower(as.character(instant_bookable)) %in% c(\"t\",\"true\"))\n\n# 3) Parse the three date-like columns (WRONG on purpose for teaching) ------\nabnb <- abnb %>%\n  mutate(\n    first_review = suppressWarnings(mdy(first_review)),\n    host_since   = suppressWarnings(mdy(host_since)),\n    last_review  = suppressWarnings(mdy(last_review))\n  )\n\n# 4) Stack the three columns into one fake \"booking date\" ------------------\nlong_wrong <- abnb %>%\n  select(\n    id, listed_price, review_scores_rating, instant_bookable,\n    first_review, host_since, last_review\n  ) %>%\n  pivot_longer(\n    cols = c(first_review, host_since, last_review),\n    names_to   = \"which_date\",\n    values_to  = \"fake_booking_date\"\n  ) %>%\n  filter(!is.na(fake_booking_date))\n\n# 5) Derive a naive season from the calendar month -------------------------\nlong_wrong <- long_wrong %>%\n  mutate(\n    Season = case_when(\n      month(fake_booking_date) %in% c(12, 1, 2) ~ \"Winter\",\n      month(fake_booking_date) %in% c(3, 4, 5)  ~ \"Spring\",\n      month(fake_booking_date) %in% c(6, 7, 8)  ~ \"Summer\",\n      TRUE                                      ~ \"Fall\"\n    )\n  )\n\n# 6) Build the gloriously wrong seasonal summary ---------------------------\nseason_summary <- long_wrong %>%\n  group_by(Season) %>%\n  summarise(\n    bookings      = n(),\n    avg_price     = mean(listed_price, na.rm = TRUE),\n    avg_rating    = mean(review_scores_rating, na.rm = TRUE),\n    instant_share = mean(instant_bookable, na.rm = TRUE)\n  ) %>%\n  ungroup() %>%\n  mutate(\n    rating_dollars = avg_rating * avg_price  # ðŸš© nonsense cross-units\n  ) %>%\n  arrange(desc(rating_dollars))\n\nbest_season <- season_summary %>% slice(1) %>% pull(Season)\n```\n\n```{r ab_flawed}\nseason_summary %>%\n  mutate(\n    `Avg Price (USD)` = dollar(avg_price, accuracy = 0.01),\n    `Avg Rating`      = number(avg_rating, accuracy = 0.01),\n    `Instant-Book %`  = percent(instant_share, accuracy = 0.01),\n    `Rating Ã— Price`  = number(rating_dollars, big.mark = \",\", accuracy = 0.01)\n  ) %>%\n  select(\n    Season,\n    `Bookings` = bookings,\n    `Avg Price (USD)`, `Avg Rating`, `Instant-Book %`, `Rating Ã— Price`\n  ) %>%\n  gt() %>%\n  gt_boland(base_size = 20, tight = FALSE) %>%\n  fmt_number(columns = \"Bookings\", decimals = 0, sep_mark = \",\")\n```\n\n## [Sample Airbnb Data]{.sr-only}\n\n```{r ab_detail}\n# 20 rows that should raise eyebrows: these are properties/listings, not bookings.\nhead_20_flags <- abnb %>%\n  select(\n    # IDs & label-like fields that scream \"listing\"\n    id, name, property_type, room_type, neighbourhood, zipcode,\n    # Capacity-level fields (not per-stay)\n    accommodates, bedrooms, beds,\n    # The three date fields we are misusing as bookings (ðŸš©)\n    host_since, first_review, last_review,\n    # Aggregated stats at the listing level (ðŸš© not a single-stay field)\n    number_of_reviews, review_scores_rating,\n    # Price & toggles\n    listed_price, instant_bookable\n  ) %>%\n  slice_head(n = 20)\n\n# Present & format for slides\nhead_20_print <- head_20_flags %>%\n  mutate(\n    instant_bookable   = ifelse(instant_bookable, \"Yes\", \"No\"),\n    listed_price       = dollar(listed_price, accuracy = 0.01),\n    number_of_reviews  = number(number_of_reviews, big.mark = \",\", accuracy = 1),\n    review_scores_rating = number(review_scores_rating, accuracy = 0.01),\n    host_since   = format(as.Date(host_since),   \"%Y-%m-%d\"),\n    first_review = format(as.Date(first_review), \"%Y-%m-%d\"),\n    last_review  = format(as.Date(last_review),  \"%Y-%m-%d\"),\n    name           = .trunc(name,          38),\n    property_type  = .trunc(property_type, 18),\n    room_type      = .trunc(room_type,     18),\n    neighbourhood  = .trunc(neighbourhood, 18),\n    zipcode        = .trunc(as.character(zipcode), 10)\n  )\n\n# Render with strict widths + tight spacing to fit 20 rows on a slide\nab_listings_tbl <- head_20_print %>%\n  select(\n    id, name, property_type, room_type, neighbourhood, zipcode,\n    accommodates, bedrooms, beds,\n    host_since, first_review, last_review,\n    number_of_reviews, review_scores_rating,\n    listed_price, instant_bookable\n  ) %>%\n  gt() %>%\n  cols_label(\n    id = \"ID\", name = \"Name\", property_type = \"Property\", room_type = \"Room\",\n    neighbourhood = \"Neighborhood\", zipcode = \"ZIP\",\n    accommodates = \"Sleeps\", bedrooms = \"BR\", beds = \"Beds\",\n    host_since = \"Host Since\", first_review = \"First Review\", last_review = \"Last Review\",\n    number_of_reviews = \"# Reviews\", review_scores_rating = \"Rating\",\n    listed_price = \"Price\", instant_bookable = \"IB?\"\n  ) %>%\n  cols_width(\n    id ~ px(68), name ~ px(220), property_type ~ px(120), room_type ~ px(110),\n    neighbourhood ~ px(120), zipcode ~ px(78), accommodates ~ px(70),\n    bedrooms ~ px(60), beds ~ px(60), host_since ~ px(100), first_review ~ px(100),\n    last_review ~ px(100), number_of_reviews ~ px(90), review_scores_rating ~ px(80),\n    listed_price ~ px(90), instant_bookable ~ px(50)\n  ) %>%\n  gt_boland(base_size = 8, tight = TRUE)\n\n\nab_listings_tbl\n```\n\n## Before we run any statisticsâ€¦\n\n<br>\n\n::: {.callout-important title=\"Guiding Question\"}\nWhat can go wrong **before** you ever run a statistical test?\n:::\n\n# What is Statistics?\n\n<br>\n\n::: {.callout-note title=\"What can go wrong...\"}\n**How could a wrong question lead to a wrong conclusion?**\n:::\n\n##  {background-image=\"media/images/w01_s03_image.png\" background-position=\"left center\" background-size=\"auto 150%\" background-repeat=\"no-repeat\" fig-alt=\"Photo of several dogs lying on a blanket; playful opener for the topic.\"}\n\n::::: columns\n::: {.column width=\"50%\"}\n:::\n\n::: {.column width=\"50%\"}\nWhat is **Statistics**?\n\nWhat is **Analytics**?\n:::\n:::::\n\n##  {background-image=\"media/images/w01_s03_image.png\" background-position=\"left center\" background-size=\"auto 150%\" background-repeat=\"no-repeat\" fig-alt=\"Three dogs on a blanket: one black, one brown, one with white markings; objective description.\"}\n\n::::: columns\n::: {.column width=\"50%\"}\n:::\n\n::: {.column width=\"50%\"}\n**Analytics** is the **art** of finding out what is in your data.\n:::\n:::::\n\n##  {background-image=\"media/images/w01_s03_image.png\" background-position=\"left center\" background-size=\"auto 150%\" background-repeat=\"no-repeat\" fig-alt=\"We don't need to see every dog in the world to know that most dogs have fur; analogy for inference.\"}\n\n::::: columns\n::: {.column width=\"50%\"}\n:::\n\n::: {.column width=\"50%\"}\nIf you can (with some effort) find the answer with certainty you are using **Analytics**.\n:::\n:::::\n\n##  {background-image=\"media/images/w01_s03_image.png\" background-position=\"left center\" background-size=\"auto 150%\" background-repeat=\"no-repeat\" fig-alt=\"When we need to get specific we need to go beyond analytics. E.g., how much food does the average dog eat?\"}\n\n::::: columns\n::: {.column width=\"50%\"}\n:::\n\n::: {.column width=\"50%\"}\n**Analytics** deals with what you know.\n\n**Statistics** deals with what you do not know.\n:::\n:::::\n\n##  {background-image=\"media/images/w01_s03_image.png\" background-position=\"left center\" background-size=\"auto 150%\" background-repeat=\"no-repeat\" fig-alt=\"Analytics frames the questions; statistics turns data into answers.\"}\n\n::::: columns\n::: {.column width=\"50%\"}\n:::\n\n::: {.column width=\"50%\"}\n**Analytics** turns curiosity into questions.\n\n**Statistics** turns data into answers.\n:::\n:::::\n\n##  {background-image=\"media/images/w01_s03_image.png\" background-position=\"left center\" background-size=\"auto 150%\" background-repeat=\"no-repeat\" fig-alt=\"A picture, a spreadsheet, or a database â€” all are data sources for analytics and statistics.\"}\n\n::::: columns\n::: {.column width=\"50%\"}\n:::\n\n::: {.column width=\"50%\"}\n**Analytics** is the **art** of finding out what is in your data.\n\n**Statistics** is the **science** of making decisions under uncertainty.\n:::\n:::::\n\n##  {background-image=\"media/images/w01_s03_image.png\" background-position=\"left center\" background-size=\"auto 150%\" background-repeat=\"no-repeat\" fig-alt=\"A picture, a spreadsheet, or a database â€” all are data sources for analytics and statistics.\"}\n\n::::: columns\n::: {.column width=\"50%\"}\n:::\n\n::: {.column width=\"50%\"}\n**Analytics** or **Statistics**\n\n-   Count the number of airbnb properties within 1 mile of Wrigley Field\n-   Predict how many bookings an airbnb property will have next year\n-   Testing whether changing cancellation policy *caused* higher satisfaction\n:::\n:::::\n\n::: notes\n-   Open with intuition: students already *do* analytics informally.\n-   Emphasize uncertainty as the key dividing line.\n-   Pause after the third fragment and ask for examples.\n:::\n\n# What does one row represent?\n\n<br>\n\n::: {.callout-note title=\"What can go wrong...\"}\n**Could the Airbnb mistake come from using the wrong unit of analysis?**\n:::\n\n## [Data at different grain levels]{.sr-only}\n\n### Calculate the Total Yearly Revenue for Each Property\n\n:::: fragment\n::: {.callout-important title=\"Gotcha! - Wrong Unit of Analysis\"}\n:::\n::::\n\n```{r ab_grain}\n# Helper (for truncation) already defined in setup chunk\n\n# 1) Identify properties to show -------------------------------------------------\nsim_ids <- abnb_sim %>% distinct(property_id) %>% pull(property_id) %>% sort()\nshow_ids <- head(sim_ids, 2)   # pick two properties for display\n\n# 2) LISTING-LEVEL TABLE (abnb): 10 total properties including the two ----------\ndesired_total <- 10\nnum_needed    <- max(0, desired_total - length(show_ids))\nextra_ids <- abnb %>%\n  filter(!id %in% show_ids) %>%\n  distinct(id) %>%\n  slice_sample(n = num_needed) %>%\n  pull(id)\n\nids_for_abnb_table <- c(show_ids, extra_ids)\n\nabnb_tbl_data <- abnb %>%\n  filter(id %in% ids_for_abnb_table) %>%\n  select(\n    id, name, room_type, listed_price, accommodates, neighbourhood,\n    bedrooms, bathrooms, beds, cancellation_policy,host_since\n  ) %>%\n  arrange(name)\n\ntbl_abnb_vt <- abnb_tbl_data %>%\n  gt() %>%\n  cols_label(\n    id = \"ID\", name = \"Name\", room_type = \"Room\", listed_price = \"List\",\n    accommodates = \"Sleeps\", neighbourhood = \"Nâ€™hood\", bedrooms = \"BR\",\n    bathrooms = \"BA\", beds = \"Beds\", cancellation_policy = \"Cancel\",host_since = \"Host Since\"\n  ) %>%\n  text_transform(\n    locations = cells_body(columns = c(name, neighbourhood, room_type, cancellation_policy)),\n    fn = function(x) .trunc(x, width = 28)\n  ) %>%\n  fmt_currency(columns = listed_price, currency = \"USD\", decimals = 0) %>%\n  cols_width(\n    id ~ px(70), name ~ px(230), room_type ~ px(110), listed_price ~ px(80),\n    accommodates ~ px(75), neighbourhood ~ px(130), bedrooms ~ px(55),\n    bathrooms ~ px(55), beds ~ px(55), cancellation_policy ~ px(110), host_since ~ px(80)\n  ) %>%\n  gt_boland(base_size = 6, tight = TRUE) %>%\n  tab_caption(md(\"**Dataset A** â€” Airbnb Rental Data\"))\n\n# 3) BOOKING-LEVEL TABLE (abnb_sim): sample 5 per property ---------------------\nabnb_sim_tbl_data <- abnb_sim %>%\n  filter(property_id %in% show_ids) %>%\n  transmute(\n    id = property_id, name, room_type, accommodates, neighbourhood,\n    checkin_date = as_date(checkin_date), nights, guest_count, status,\n    price_per_night, total_price = tidyr::replace_na(total_price, 0)\n  ) %>%\n  arrange(name, checkin_date) %>%\n  group_by(id) %>%\n  filter(row_number() %in% sample.int(n(), size = min(5, n()), replace = FALSE)) %>%\n  ungroup() %>%\n  arrange(name, checkin_date)\n\ntbl_abnb_sim_vt <- abnb_sim_tbl_data %>%\n  gt() %>%\n  cols_label(\n    id = \"ID\", name = \"Name\", room_type = \"Room\", accommodates = \"Sleeps\",\n    neighbourhood = \"Nâ€™hood\", checkin_date = \"Checkâ€‘in\", nights = \"Nts\",\n    guest_count = \"Guests\", status = \"Status\", price_per_night = \"Price/Nt\",\n    total_price = \"Total\"\n  ) %>%\n  text_transform(\n    locations = cells_body(columns = c(name, neighbourhood, room_type, status)),\n    fn = function(x) .trunc(x, width = 24)\n  ) %>%\n  fmt_currency(columns = c(price_per_night, total_price), currency = \"USD\", decimals = 0) %>%\n  cols_width(\n    id ~ px(70), name ~ px(220), room_type ~ px(100), accommodates ~ px(75),\n    neighbourhood ~ px(120), checkin_date ~ px(90), nights ~ px(45),\n    guest_count ~ px(60), status ~ px(90), price_per_night ~ px(90),\n    total_price ~ px(100)\n  ) %>%\n  gt_boland(base_size = 6.25, tight = TRUE) %>%\n  tab_caption(md(\"**Dataset B** â€” Airbnb Rental Data\"))\n```\n\n```{r ab_property}\n# Listing-level snapshot (fragment 1)\ntbl_abnb_vt\ntbl_abnb_sim_vt\n```\n\n```{r ab_bookings}\n# Booking-level snapshot (fragment 2)\n\n```\n\n## [Rows vs Columns]{.sr-only}\n\n::::: columns\n::: {.column width=\"50%\"}\n### Columns\n\n![](media/images/w01_s19_image.png){fig-alt=\"Icon emphasizing the concept of columnsâ€”variablesâ€”in a dataset.\" width=\"100%\"}\n:::\n\n::: {.column width=\"50%\"}\n<br><br><br><br><br>\n\n### Rows\n\n![](media/images/w01_s19_image.jpg){fig-alt=\"Icon emphasizing the concept of rowsâ€”observationsâ€”in a dataset.\" width=\"100%\"}\n:::\n:::::\n\n## Unit of Analysis\n\n::::::: columns\n::: column-page\n**What does each *thingie* (row, observation, grain) of this data represent?**\n:::\n\n:::: {.column width=\"58%\"}\n::: tight-list\n-   Everyone in a *zipcode*\n-   Individual consumers\n-   Individual purchases\n-   GDP of an economy\n-   Population of a planet\n:::\n::::\n\n::: {.column width=\"42%\"}\n![](media/images/w01_s14_image.png){fig-alt=\"Photo of several dogs lying on a blanket; playful opener for the topic.\" height=\"65%\"}\n:::\n:::::::\n\n## Unit of Analysis\n\n<br><br>\n\n### Rows are never 'just rows'\n\n<br><br>\n\n::: {.callout-important title=\"Critical Insight\"}\nIf you misunderstand the unit of analysis, **every result is wrong**, even with perfect code.\n:::\n\n## Data Grouping: Cross-Sectional {background-image=\"media/images/w01_s15_image.jpeg\" background-size=\"cover\" background-opacity=\"0.95\" fig-alt=\"Freezeâ€‘frame droplet illustrating a crossâ€‘sectional snapshot at a single point in time.\"}\n\n## Data Grouping: Time-Series\n\n![](media/images/w01_s16_image.jpeg){fig-alt=\"Growth sequence image suggesting change over time in a timeâ€‘series.\" height=\"85%\"}\n\n## Data Grouping: Panel\n\n![](media/images/w01_s17_image.jpeg){.r-stretch fig-alt=\"Gridâ€‘style visual suggesting repeated measures on multiple units across time (panel data).\" fig-align=\"right\" height=\"100%\"}\n\n# Data Structure\n\n<br>\n\n::: {.callout-note title=\"What can go wrong...\"}\n**Could shape of my data change what answers are even possible?**\n:::\n\n## [Tall vs Wide Data]{.sr-only}\n\n### Summarize total minutes of sleep by month and location\n\n:::: fragment\n::: {.callout-important title=\"Gotcha! - Wrong Data Structure\"}\n:::\n::::\n\n```{r sleep_data}\nlibrary(here)\n\n# ---- 1) Load with explicit column types ----\ncsv_path      <- here(\"week01\", \"data\", \"sleep_tracking_Jan-Jun_2025_with_zip.csv\")\ncsv_path_zips <- here(\"week01\", \"data\", \"simulated_zip_profiles.csv\")\n\n# 1) Load data --------------------------------------------------------------\nsleep_zips <- read_csv(csv_path_zips)\n\nsleep <- read_csv(\n  file = csv_path,\n  col_types = cols(\n    Date          = col_character(),\n    DayOfWeek     = col_character(),\n    Month         = col_character(),\n    PersonName    = col_character(),\n    Gender        = col_character(),\n    Location      = col_character(),\n    SleepEventType= col_character(),\n    StartTime     = col_character(),\n    EndTime       = col_character(),\n    TotalMinutes  = col_integer(),\n    REMMinutes    = col_integer(),\n    DeepMinutes   = col_integer(),\n    LightMinutes  = col_integer(),\n    SleepQuality  = col_double(),\n    ZipCode       = col_character()\n  ),\n  show_col_types = FALSE\n)\n\n# ---- 2) Fix Date if it came in as an Excel serial ----\nis_excel_serial <- function(x_chr) {\n  all(str_detect(x_chr, \"^\\\\d{4,5}$\"), na.rm = TRUE)\n}\n\nif (is_excel_serial(sleep$Date)) {\n  sleep$Date <- as.Date(as.numeric(sleep$Date), origin = \"1899-12-30\")\n} else {\n  parsed1 <- suppressWarnings(ymd(sleep$Date, quiet = TRUE))\n  parsed2 <- ifelse(is.na(parsed1), suppressWarnings(mdy(sleep$Date, quiet = TRUE)), parsed1)\n  sleep$Date <- as.Date(parsed2)\n}\n\n# ---- 3) Robust parsers for StartTime/EndTime ----\nparse_start_end <- function(x_chr) {\n  x_chr <- str_trim(x_chr)\n  parse_date_time(\n    x_chr,\n    orders = c(\n      \"Y-m-d H:M\", \"Y-m-d H:M:S\",\n      \"m/d/Y I:M p\", \"m/d/Y I:M:S p\",\n      \"m/d/y I:M p\", \"m/d/y I:M:S p\"\n    ),\n    tz = \"UTC\"\n  )\n}\n\nsleep$StartTime_dt <- parse_start_end(sleep$StartTime)\nsleep$EndTime_dt   <- parse_start_end(sleep$EndTime)\n\nfmt_time_12h <- function(dt) {\n  ifelse(\n    is.na(dt), NA_character_,\n    str_to_upper(format(dt, \"%I:%M %p\")) |>\n      str_replace(\"^0\", \"\") |>\n      str_replace_all(\"AM\", \"A.M.\") |>\n      str_replace_all(\"PM\", \"P.M.\")\n  )\n}\n\nfmt_pct <- function(x) paste0(round(100 * x), \"%\")\n```\n\n```{r sleep_filter}\nweek_data <- sleep %>%\n  filter(\n    Date >= \"2025-01-05\",\n    Date <= \"2025-01-11\",\n    PersonName %in% c(\"Mike\", \"Cam\"),\n    SleepEventType == \"Main\"\n  ) %>%\n  select(\n    Name = PersonName, Gender, Location, Date, DayOfWeek, TotalMinutes\n  ) %>%\n  group_by(Name, Gender, Location, Date, DayOfWeek) %>%\n  summarise(TotalMinutes = sum(TotalMinutes), .groups = \"drop\")\n```\n\n::::: columns\n::: {.column width=\"30%\"}\n```{r sleep_tall}\n\n\n\ntall_week <- sleep %>%\n  filter(\n    Date >= \"2025-01-05\",\n    Date <= \"2025-01-11\",\n    PersonName %in% c(\"Mike\", \"Cam\"),\n    SleepEventType == \"Main\"\n  ) %>%\n  select(\n    Name = PersonName, Gender, Location, Date, DayOfWeek, TotalMinutes\n  ) %>%\n  group_by(Name, Gender, Location, Date, DayOfWeek) %>%\n  summarise(TotalMinutes = sum(TotalMinutes), .groups = \"drop\") %>%\n  mutate(across(-Name, as.character)) %>%\n  pivot_longer(cols = -Name, names_to = \"Variable\", values_to = \"Value\") %>%\n  arrange(Name, Variable)\n\n\ntall_week %>%\n  gt(rowname_col = \"Name\") %>%\n  tab_header(title = md(\"**Tall â€” More rows, fewer columns**\")) %>%\n  cols_label(Variable = \"Variable\", Value = \"Value\") %>%\n  fmt_missing(everything(), missing_text = \"\") %>%\n  gt_boland(base_size = 12, tight = FALSE) %>%\n  tab_options(\n    container.height = px(420),\n    container.overflow.y = TRUE\n  )\n```\n:::\n\n::: {.column width=\"70%\"}\n```{r sleep_wide}\nwide_week <- week_data %>%\n  select(Name, Gender, Location, Date, TotalMinutes) %>%\n  pivot_wider(names_from = Date, values_from = TotalMinutes) %>%\n  arrange(Name)\n\nwide_week %>%\n  gt() %>%\n  tab_header(title = md(\"**Wide â€” More columns, fewer rows**\")) %>%\n  fmt_missing(everything(), missing_text = \"\") %>%\n  gt_boland(base_size = 12, tight = FALSE) %>%\n  tab_options(container.overflow.x = TRUE, table.width = pct(120))\n```\n:::\n:::::\n\n## Data Types\n\n<br>\n\n### Categories\n\nTrue/False â†’ `logical`\\\nCategorical â†’ `factor`\\\nOrdinal â†’ `factor`\n\n<br>\n\n### Numbers\n\nDiscrete â†’ `integer`\\\nContinuous â†’ `double`\n\n------------------------------------------------------------------------\n\n## Measurement Scales\n\n![](../shared/images/NOIR.svg){width=\"100%\" height=\"700px\" fig-alt=\"Visual representing measurement scales Nominal, Ordinal, Interval, Ratio and their common uses.\"}\n\n## Observations - Atomic Data\n\n```{r name:sleep_desc}\n# ---- 5) Function to build the two tables for a chosen person & date ----\nmake_sleep_tables <- function(data, person = \"Mike\", date_input = \"2025-01-03\") {\n  date_val <- if (inherits(date_input, \"Date\")) date_input else as.Date(date_input)\n  row <- data %>%\n    filter(PersonName == person, Date == date_val, SleepEventType == \"Main\") %>%\n    arrange(StartTime_dt) %>% slice(1)\n  if (nrow(row) == 0) stop(\"No 'Main' sleep row found for that person/date.\")\n\n  categories_df <- tibble::tibble(\n    Label = c(\"Name\", \"Date\", \"Gender\", \"Location\", \"ZipCode\"),\n    Value = c(row$PersonName, format(row$Date, \"%m/%d/%Y\"), row$Gender, row$Location, row$ZipCode)\n  )\n  numbers_df <- tibble::tibble(\n    Label = c(\"Start Time\", \"End Time\", \"R.E.M.\", \"Deep Sleep\", \"Light Sleep\", \"Total Sleep\", \"Quality\"),\n    Value = c(\n      fmt_time_12h(row$StartTime_dt), fmt_time_12h(row$EndTime_dt),\n      paste0(row$REMMinutes, \" Minutes\"), paste0(row$DeepMinutes, \" Minutes\"),\n      paste0(row$LightMinutes, \" Minutes\"), as.character(row$TotalMinutes), fmt_pct(row$SleepQuality)\n    )\n  )\n  list(categories = categories_df, numbers = numbers_df)\n}\n\ntables <- make_sleep_tables(sleep, person = \"Mike\", date_input = \"2025-01-03\")\ncategories_df <- tables$categories\nnumbers_df    <- tables$numbers\n```\n\n:::::: columns\n::: {.column width=\"30%\"}\n```{r sleep_categories}\n\ncategories_df |>\n  gt() |>\n  tab_header(title = md(\"**Categories**\")) |>\n  cols_label(Label = \"\", Value = \"\") |>\n  gt_boland(base_size = 12, tight = FALSE)\n```\n:::\n\n::: {.column width=\"40%\"}\n![](media/images/w01_s21_image.jpeg){fig-alt=\"Single cube emphasizing an atomic unit of observation in the data.\" width=\"100%\"}\n:::\n\n::: {.column width=\"30%\"}\n```{r sleep_numbers}\n\nnumbers_df |>\n  gt() |>\n  tab_header(title = md(\"**Numbers**\")) |>\n  cols_label(Label = \"\", Value = \"\") |>\n  gt_boland(base_size = 12, tight = FALSE)\n```\n:::\n::::::\n\n## [Summarized Data]{.sr-only}\n\n:::::::::: columns\n:::: {.column width=\"30%\"}\n### Dimensions\n\n::: tight-list\n-   Categories\n-   Filters\n-   Axis Labels\n:::\n::::\n\n::: {.column width=\"40%\"}\n<br> <br> <br> <br> ![](media/images/w01_s22_stack.png){fig-alt=\"An ordered stack of multiple atomic units making it possible to summarize the data with measures and summary statistics.\" width=\"100%\"}\n:::\n\n:::::: {.column width=\"30%\"}\n### Measures\n\n::: tight-list\n-   Averages\n-   Standard Deviation\n-   Counts\n-   Sums\n:::\n\n::: fragment\n```{r sleep_summary}\njune_glamping <- sleep %>% filter(Month == \"June\", Location == \"Camping\")\n# june_glamping <- june_glamping %>% filter(SleepEventType == \"Main\")\n\nmean_minutes   <- mean(june_glamping$TotalMinutes, na.rm = TRUE)\nmedian_minutes <- median(june_glamping$TotalMinutes, na.rm = TRUE)\navg_quality    <- mean(june_glamping$SleepQuality, na.rm = TRUE)\nn_records      <- nrow(june_glamping)\n\nsummary_vertical <- tibble::tibble(\n  Summary = c(\n    glue(\"Mean = {sprintf('%.2f', mean_minutes)} Minutes\"),\n    glue(\"Median = {round(median_minutes)} Minutes\"),\n    glue(\"Quality = {percent(avg_quality, accuracy = 0.01)}\"),\n    glue(\"N Records = {comma(n_records)}\")\n  )\n)\n\nsummary_vertical |>\n  gt() |>\n  tab_header(title = md(\"**June Camping**\")) |>\n  cols_label(Summary = \"\") |>\n  gt_boland(base_size = 16, tight = FALSE)\n```\n:::\n\n::: fragment\n```{r sleep_summary_jan}\njan_home <- sleep %>% filter(Month == \"January\", Location == \"Home\")\n# june_glamping <- june_glamping %>% filter(SleepEventType == \"Main\")\n\nmean_minutes_JH   <- mean(jan_home$TotalMinutes, na.rm = TRUE)\nmedian_minutes_JH <- median(jan_home$TotalMinutes, na.rm = TRUE)\navg_quality_JH    <- mean(jan_home$SleepQuality, na.rm = TRUE)\nn_records_JH     <- nrow(jan_home)\n\nsummary_vertical <- tibble::tibble(\n  Summary = c(\n    glue(\"Mean = {sprintf('%.2f', mean_minutes_JH)} Minutes\"),\n    glue(\"Median = {round(median_minutes_JH)} Minutes\"),\n    glue(\"Quality = {percent(avg_quality_JH, accuracy = 0.01)}\"),\n    glue(\"N Records = {comma(n_records_JH)}\")\n  )\n)\n\nsummary_vertical |>\n  gt() |>\n  tab_header(title = md(\"**January Home**\")) |>\n  cols_label(Summary = \"\") |>\n  gt_boland(base_size = 16, tight = FALSE)\n```\n:::\n::::::\n::::::::::\n\n## Tall vs Wide\n\n```{r sleep_dims_cats}\n# --- Define columns ---\ndims <- c(\"Date\",\"DayOfWeek\",\"Month\",\"PersonName\",\"Gender\",\"Location\",\"SleepEventType\")\nmeas <- c(\"StartTime\",\"EndTime\",\"TotalMinutes\",\"REMMinutes\",\"DeepMinutes\",\"LightMinutes\",\"SleepQuality\")\n\ntbl20 <- sleep %>% select(all_of(dims), all_of(meas)) %>% slice_head(n = 15)\n\n# Tableau-like colors (approx)\ntableau_blue  <- \"#4E79A7\"\ntableau_green <- \"#59A14F\"\nblue_fill     <- \"#EAF2FB\"\ngreen_fill    <- \"#EAF6EA\"\nheader_text   <- \"white\"\n\n\ntbl20 |>\n  gt() |>\n  tab_spanner(label = \"Dimensions\", columns = all_of(dims)) |>\n  tab_spanner(label = \"Measures\",   columns = all_of(meas)) |>\n  fmt_percent(columns = \"SleepQuality\", decimals = 2) |>\n  tab_style(style = cell_fill(color = blue_fill),  locations = cells_body(columns = all_of(dims))) |>\n  tab_style(style = cell_fill(color = green_fill), locations = cells_body(columns = all_of(meas))) |>\n  tab_style(style = list(cell_fill(color = tableau_blue),  cell_text(color = header_text)), locations = cells_column_spanners(spanners = \"Dimensions\")) |>\n  tab_style(style = list(cell_fill(color = tableau_green), cell_text(color = header_text)), locations = cells_column_spanners(spanners = \"Measures\")) |>\n  gt_boland(base_size = 12, tight = FALSE) |>\n  cols_label(\n    SleepEventType = \"EventType\",\n    REMMinutes = \"REMMinutes\", DeepMinutes = \"DeepMinutes\",\n    LightMinutes = \"LightMinutes\", TotalMinutes = \"TotalMinutes\",\n    SleepQuality = \"SleepQuality\"\n  )\n```\n\n## Principles of Tidy Data\n\n<br>\n\n-   *Each variable you measure should be in one column*\n-   *Each observation of that variable should be in a different row*\n-   *There should be one table for each type of observational unit*\n-   *If you have multiple tables you need a key to link them*\n\n<br><br><br>\n\n:::: fragment\n::: {.callout-important title=\"Nerd Alert.\"}\nTidy Data principles are a **solution to a problem**, not rules that **must** be followed.\n:::\n::::\n\n```{r tidy_tables}\n# ---------- TABLE A: sleep (first 10 rows with selected columns) ----------\nsleep_tbl_data <- sleep %>% select(PersonName, Gender, Location, ZipCode, TotalMinutes, SleepQuality) %>% head(10)\n\n\t\t# Render A\nsleep_tbl <- sleep_tbl_data %>%\n  gt() %>%\n  cols_label(\n    PersonName = \"Name\", Gender = \"Gender\", Location = \"Location\",\n    ZipCode = \"ZIP\", TotalMinutes = \"Minutes\", SleepQuality = \"Quality\"\n  ) %>%\n  cols_width(\n    PersonName ~ px(180), Gender ~ px(90), Location ~ px(130), ZipCode ~ px(90),\n    TotalMinutes ~ px(90), SleepQuality ~ px(90)\n  ) %>%\n  gt_boland(base_size = 16, tight = TRUE) %>%\n  tab_caption(md(\"**Sleep (first 10):** `PersonName, Gender, Location, ZipCode, TotalMinutes, SleepQuality`\"))\n\n# ---------- TABLE B: sleep_zips (first 10 rows) ----------\nsleep_zips_tbl_data <- sleep_zips %>% head(10)\n\nsleep_zips_tbl <- sleep_zips_tbl_data %>%\n  gt() %>%\n  cols_label(\n    zip = \"ZIP\", city = \"City\", state = \"State\", population = \"Population\",\n    crime_rate_per_100k = \"Crime per 100k\", avg_sunny_days_per_year = \"Sunny Days\"\n  ) %>%\n  fmt_number(columns = population,              decimals = 0, sep_mark = \",\") %>%\n  fmt_number(columns = crime_rate_per_100k,     decimals = 0, sep_mark = \",\") %>%\n  fmt_number(columns = avg_sunny_days_per_year, decimals = 0) %>%\n  cols_width(\n    zip ~ px(90), city ~ px(150), state ~ px(70), population ~ px(110),\n    crime_rate_per_100k ~ px(120), avg_sunny_days_per_year ~ px(100)\n  ) %>%\n  gt_boland(base_size = 16, tight = TRUE) %>%\n  tab_caption(md(\"**Sleep ZIP Profiles (first 10):** `zip, city, state, population, crime_rate_per_100k, avg_sunny_days_per_year`\"))\n```\n\n## Tidy Data - Principles 1-3\n\n```{r tidy_base}\n# ---- Display both tables on the slide ----\nsleep_tbl\n```\n\n## Tidy Data - Principle 4\n\n```{r tidy_join}\nsleep_zips_tbl\n```\n\n# Acronyms to the Rescue (ATTR)\n\n<br>\n\n::: {.callout-note title=\"What can go wrong...\"}\n**Could messy or inconsistent data break every conclusion downstream?**\n:::\n\n## [ETL Process - Extract]{.sr-only}\n\n::: text-center\n**Extract** \\| Transform \\| Load\n:::\n\n:::::: columns\n::: {.column width=\"33%\"}\nStructured Data\n\n![](media/images/w01_s11_database.png){fig-alt=\"Icon illustrating extracting from an ordered database in the ETL workflow.\" width=\"80%\"}\n:::\n\n::: {.column width=\"34%\"}\nThird Party\n\n![](media/images/w01_s11_census.png){fig-alt=\"Icon illustrating extracting from a third party source of structured data in the ETL workflow.\" width=\"80%\"}\n:::\n\n::: {.column width=\"33%\"}\nUnstructured Data\n\n![](media/images/w01_s11_image.png){fig-alt=\"Terminal/connector graphic showing extracted data may be unstructured or streaming ETL operations.\" width=\"80%\"}\n:::\n::::::\n\n## [ETL Process - Transform]{.sr-only}\n\n::::::: text-center\nExtract \\| **Transform** \\| Load\n\n:::::: columns\n::: {.column width=\"25%\"}\n![](../shared/images/logo_Excel.png){width=\"100px\" fig-alt=\"Microsoft Excel Logo\"}\n\n![](media/images/w01_s11_census.png){width=\"100px\" fig-alt=\"Icon illustrating extracting from a third party source of structured data in the ETL workflow.\"}\n\n![](../shared/images/logo_R.png){width=\"100px\" fig-alt=\"R Language Logo\"}\n\n![](../shared/images/logo_Database.png){width=\"100px\" fig-alt=\"Generic Database Logo\"}\n\n![](media/images/w01_s11_image.png){width=\"100px\" fig-alt=\"Terminal/connector graphic showing extracted data may be unstructured or streaming ETL operations.\"}\n:::\n\n::: {.column width=\"50%\"}\n![](media/images/w01_s20_grinder.png){width=\"100%\" fig-alt=\"Transformation metaphor: grinder processing data.\"}\n:::\n\n::: {.column width=\"25%\"}\n:::\n::::::\n:::::::\n\n## [ETL Process - Transform Example]{.sr-only}\n\n::: text-center\nExtract \\| **Transform** \\| Load\n:::\n\n```{r}\n# ---- 0) Where the file lives ----\npath <- here(\"week01\", \"data\", \"messy_zip_54601.csv\")\n\n# ---- 1) Load the messy data (20 rows) ----\nmessy_zip <- read_csv(path, show_col_types = FALSE)\n\n# ---- 2) Truncate the very long column so the table fits on a slide ----\nTRUNC_WIDTH <- 60\nmessy_zip_trunc <- messy_zip %>%\n  mutate(\n    everything_raw = ifelse(\n      is.na(everything_raw),\n      everything_raw,\n      str_trunc(everything_raw, width = TRUNC_WIDTH, side = \"right\", ellipsis = \"â€¦\")\n    )\n  )\n\n# ---- 3) Render ALL 20 rows with slide theme ----\nmessy_zip_trunc %>%\n  select(zip_value,state_value,county_value,population_value,fips_county,everything_raw) %>%\n  gt() %>%\n  cols_width(\n    zip_value ~ px(110), state_value ~ px(110), county_value ~ px(140),\n    population_value ~ px(130), fips_county ~ px(95), everything_raw ~ px(380)\n  ) %>%\n  gt_boland(base_size = 10, tight = TRUE) %>%\n  tab_caption(md(\"**Messy ZIP 54601**\"))\n```\n\n## [ETL Process - Load]{.sr-only}\n\n::::::: text-center\nExtract \\| Transform \\| **Load**\n\n:::::: columns\n::: {.column width=\"25%\"}\n![](../shared/images/logo_Excel.png){width=\"100px\" fig-alt=\"Microsoft Excel Logo\"}\n\n![](media/images/w01_s11_census.png){width=\"100px\" fig-alt=\"Icon illustrating extracting from a third party source of structured data in the ETL workflow.\"}\n\n![](../shared/images/logo_R.png){width=\"100px\" fig-alt=\"R Language Logo\"}\n\n![](../shared/images/logo_Database.png){width=\"100px\" fig-alt=\"Generic Database Logo\"}\n\n![](media/images/w01_s11_image.png){width=\"100px\" fig-alt=\"Terminal/connector graphic showing extracted data may be unstructured or streaming ETL operations.\"}\n:::\n\n::: {.column width=\"50%\"}\n![](media/images/w01_s20_grinder.png){width=\"100%\" fig-alt=\"Transformation metaphor: grinder processing data.\"}\n:::\n\n::: {.column width=\"25%\"}\n![](../shared/images/logo_Tableau.jpeg){width=\"100px\" fig-alt=\"Tableau Logo\"}\n\n![](../shared/images/logo_Database.png){width=\"100px\" fig-alt=\"Generic Database Logo\"}\n\n![](../shared/images/logo_Excel.png){width=\"100px\" fig-alt=\"Microsoft Excel Logo\"}\n\n![](../shared/images/logo_R.png){width=\"100px\" fig-alt=\"R Language Logo\"}\n\n![](../shared/images/logo_SPSS.png){width=\"100px\" fig-alt=\"SPSS Logo\"}\n:::\n::::::\n:::::::\n\n## Tableau\n\n![](media/images/w01_s26_image.png){fig-alt=\"Tableau branding indicating the visualization tool introduced in this course.\" width=\"100%\"}\n\n## Posit.cloud\n\n![](media/images/w01_s27_image.png){fig-alt=\"Posit Cloud branding indicating a browserâ€‘based RStudio environment for analysis.\" width=\"100%\"}\n\n## [Coding in R]{.sr-only}\n\n```{r setup_eco}\nlibrary(eco230r)\nlibrary(dplyr)\n```\n\n::::::::: columns\n::: {.column width=\"10%\"}\n![](../shared/images/logo_R.png){width=\"100%\" fig-alt=\"R Language Logo\"}\n:::\n\n::::::: {.column width=\"90%\"}\n::: fragment\n```{r idt_code, echo=TRUE, results=\"hide\"}\nabnb %>% idt(listed_price~instant_bookable)\n```\n:::\n\n::: fragment\n```{r idt_results, echo=FALSE, results=\"show\"}\nabnb %>% idt(listed_price~instant_bookable)\n```\n:::\n\n::: fragment\n```{r ano_code, echo=TRUE, results=\"hide\" }\nabnb %>% ano(listed_price~room_type)\n```\n:::\n\n::: fragment\n```{r ano_results, echo=FALSE, results=\"show\" }\nabnb %>% ano(listed_price~room_type)\n```\n:::\n:::::::\n:::::::::\n\n## Soâ€¦ what actually went wrong with the Airbnb analysis?\n\n<br>\n\n::: tight-list\n-   Wrong unit of analysis\\\n-   Wrong time fields\\\n-   Wrong data structure\\\n-   Wrong aggregation\\\n-   Wrong assumptions about what the data measures\\\n:::\n\n<br>\n\n::: {.callout-tip title=\"What is your data?\"}\nEverything broke *before* statistics.\n:::\n\n## [Summary and Prime Directive]{.sr-only}\n\n<br><br><br>\n\n### Before running any statistics, what are the three questions you must answer about a dataset?\n\n<br> 1. What does one row represent? <br> 2. What kind of variables do I have? <br> 3. What question can this data answer?"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","css":["../shared/styles/accessibility.css"],"toc":false,"self-contained":false,"output-file":"week_01.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.8.27","auto-stretch":true,"editor":"visual","title":"ECO 230 Section 012","author":"Mike Boland, MBA","theme":["default","../shared/styles/boland-reveal.scss"],"slideNumber":true,"hash":true,"controls":true,"transition":"fade","pdf-export":true,"center":false,"margin":0}}},"projectFormats":["html"]}